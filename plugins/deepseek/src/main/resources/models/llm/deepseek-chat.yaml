# DeepSeek Chat æ¨¡å‹é…ç½®
model:
  # æ¨¡å‹å”¯ä¸€æ ‡è¯†ç¬¦
  code: "deepseek-chat"
  # æ¨¡å‹æ˜¾ç¤ºåç§°
  name: "DeepSeek Chat"
  # æ¨¡å‹è¯¦ç»†æè¿°
  description: "DeepSeekçš„é€šç”¨å¯¹è¯æ¨¡å‹ï¼Œé€‚ç”¨äºå„ç§èŠå¤©å’Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡"
  # æ¨¡å‹å›¾æ ‡
  icon: "ğŸ§ "
  # æ‰€å±æä¾›å•†ä»£ç 
  provider: "deepseek"
  # æ¨¡å‹ç±»å‹ï¼šchat/completion/embedding/image
  modelType: "chat"
  # æ¨¡å‹ç‰ˆæœ¬å·
  version: "1.0"
  # æ’åºæƒé‡ï¼Œæ•°å€¼è¶Šå°æ’åºè¶Šé å‰
  sortOrder: 1
  # æ˜¯å¦å¯ç”¨,é»˜è®¤å¯ç”¨
  enabled: true
  # æ¨¡å‹æ”¯æŒçš„åŠŸèƒ½åˆ—è¡¨
  capabilities:
    - "chat"              # æ”¯æŒå¯¹è¯èŠå¤©
    - "completion"        # æ”¯æŒæ–‡æœ¬è¡¥å…¨
    - "analysis"          # æ”¯æŒæ–‡æœ¬åˆ†æ
  # æ¨¡å‹é…ç½®å‚æ•°å®šä¹‰
  configSchemas:
    # æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¾“å‡ºè¶Šéšæœº
    - name: temperature
      type: number
      title: æ¸©åº¦å‚æ•°
      description: æ§åˆ¶è¾“å‡ºçš„éšæœºæ€§ï¼Œå€¼è¶Šé«˜è¾“å‡ºè¶Šéšæœº
      defaultValue: 0.7
      min: 0
      max: 2
    # æœ€å¤§ä»¤ç‰Œæ•°ï¼Œç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§ä»¤ç‰Œæ•°é‡
    - name: max_tokens
      type: integer
      title: æœ€å¤§ä»¤ç‰Œæ•°
      description: ç”Ÿæˆæ–‡æœ¬çš„æœ€å¤§ä»¤ç‰Œæ•°é‡
      defaultValue: 4096
      min: 1
      max: 8192
    # æ ¸é‡‡æ ·å‚æ•°ï¼Œæ§åˆ¶è¯æ±‡é€‰æ‹©çš„å¤šæ ·æ€§
    - name: top_p
      type: number
      title: æ ¸é‡‡æ ·å‚æ•°
      description: æ ¸é‡‡æ ·å‚æ•°ï¼Œæ§åˆ¶è¯æ±‡é€‰æ‹©çš„å¤šæ ·æ€§
      defaultValue: 0.95
      min: 0
      max: 1
model: deepseek-chat
label:
  zh_Hans: deepseek-chat
  en_US: deepseek-chat
model_type: llm
features:
  - agent-thought
  - tool-call
  - multi-tool-call
  - stream-tool-call
model_properties:
  mode: chat
  context_size: 128000
parameter_rules:
  - name: temperature
    use_template: temperature
    type: float
    default_value: 1
    min: 0.0
    max: 2.0
    help:
      zh_Hans: æ§åˆ¶ç”Ÿæˆç»“æœçš„å¤šæ ·æ€§å’Œéšæœºæ€§ã€‚æ•°å€¼è¶Šå°ï¼Œè¶Šä¸¥è°¨ï¼›æ•°å€¼è¶Šå¤§ï¼Œè¶Šå‘æ•£ã€‚
      en_US: Control the diversity and randomness of generated results. The smaller the value, the more rigorous it is; the larger the value, the more divergent it is.
  - name: max_tokens
    use_template: max_tokens
    type: int
    default_value: 4096
    min: 1
    max: 8192
    help:
      zh_Hans: æŒ‡å®šç”Ÿæˆç»“æœé•¿åº¦çš„ä¸Šé™ã€‚å¦‚æœç”Ÿæˆç»“æœæˆªæ–­ï¼Œå¯ä»¥è°ƒå¤§è¯¥å‚æ•°ã€‚
      en_US: Specifies the upper limit on the length of generated results. If the generated results are truncated, you can increase this parameter.
  - name: top_p
    use_template: top_p
    type: float
    default_value: 1
    min: 0.01
    max: 1.00
    help:
      zh_Hans: æ§åˆ¶ç”Ÿæˆç»“æœçš„éšæœºæ€§ã€‚æ•°å€¼è¶Šå°ï¼Œéšæœºæ€§è¶Šå¼±ï¼›æ•°å€¼è¶Šå¤§ï¼Œéšæœºæ€§è¶Šå¼ºã€‚ä¸€èˆ¬è€Œè¨€ï¼Œtop_p å’Œ temperature ä¸¤ä¸ªå‚æ•°é€‰æ‹©ä¸€ä¸ªè¿›è¡Œè°ƒæ•´å³å¯ã€‚
      en_US: Control the randomness of generated results. The smaller the value, the weaker the randomness; the larger the value, the stronger the randomness. Generally speaking, you can adjust one of the two parameters top_p and temperature.
  - name: logprobs
    label:
      en_US: Logprobs
    help:
      zh_Hans: æ˜¯å¦è¿”å›æ‰€è¾“å‡º token çš„å¯¹æ•°æ¦‚ç‡ã€‚å¦‚æœä¸º trueï¼Œåˆ™åœ¨ message çš„ content ä¸­è¿”å›æ¯ä¸ªè¾“å‡º token çš„å¯¹æ•°æ¦‚ç‡ã€‚
      en_US: Whether to return the log probability of the output token. If true, returns the log probability of each output token in the content of message .
    type: boolean
  - name: top_logprobs
    label:
      en_US: Top Logprobs
    type: int
    default_value: 0
    min: 0
    max: 20
    help:
      zh_Hans: ä¸€ä¸ªä»‹äº 0 åˆ° 20 ä¹‹é—´çš„æ•´æ•° Nï¼ŒæŒ‡å®šæ¯ä¸ªè¾“å‡ºä½ç½®è¿”å›è¾“å‡ºæ¦‚ç‡ top N çš„ tokenï¼Œä¸”è¿”å›è¿™äº› token çš„å¯¹æ•°æ¦‚ç‡ã€‚æŒ‡å®šæ­¤å‚æ•°æ—¶ï¼Œlogprobs å¿…é¡»ä¸º trueã€‚
      en_US: An integer N between 0 and 20, specifying that each output position returns the top N tokens with output probability, and returns the logarithmic probability of these tokens. When specifying this parameter, logprobs must be true.
  - name: frequency_penalty
    use_template: frequency_penalty
    default_value: 0
    min: -2.0
    max: 2.0
    help:
      zh_Hans: ä»‹äº -2.0 å’Œ 2.0 ä¹‹é—´çš„æ•°å­—ã€‚å¦‚æœè¯¥å€¼ä¸ºæ­£ï¼Œé‚£ä¹ˆæ–° token ä¼šæ ¹æ®å…¶åœ¨å·²æœ‰æ–‡æœ¬ä¸­çš„å‡ºç°é¢‘ç‡å—åˆ°ç›¸åº”çš„æƒ©ç½šï¼Œé™ä½æ¨¡å‹é‡å¤ç›¸åŒå†…å®¹çš„å¯èƒ½æ€§ã€‚
      en_US: A number between -2.0 and 2.0. If the value is positive, new tokens are penalized based on their frequency of occurrence in existing text, reducing the likelihood that the model will repeat the same content.
  - name: response_format
    label:
      zh_Hans: å›å¤æ ¼å¼
      en_US: Response Format
    type: string
    help:
      zh_Hans: æŒ‡å®šæ¨¡å‹å¿…é¡»è¾“å‡ºçš„æ ¼å¼
      en_US: specifying the format that the model must output
    required: false
    options:
      - text
      - json_object
pricing:
  input: "2"
  output: "8"
  unit: "0.000001"
  currency: RMB
